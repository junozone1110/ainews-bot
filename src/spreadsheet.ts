import { parse } from 'csv-parse/sync';

/**
 * Google Spreadsheetã‹ã‚‰ã‚µã‚¤ãƒˆURLã®ãƒªã‚¹ãƒˆã‚’å–å¾—
 * @param csvUrl Spreadsheetã®CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆURL
 * @returns ã‚µã‚¤ãƒˆURLã®é…åˆ—
 */
export async function fetchSiteUrls(csvUrl: string): Promise<string[]> {
  try {
    console.log('ğŸ“Š Fetching site URLs from spreadsheet...');
    
    // CSVã‚’ãƒ•ã‚§ãƒƒãƒ
    const response = await fetch(csvUrl);
    
    if (!response.ok) {
      throw new Error(`Failed to fetch spreadsheet: ${response.status} ${response.statusText}`);
    }
    
    const csvText = await response.text();
    
    // CSVã‚’ãƒ‘ãƒ¼ã‚¹
    const records = parse(csvText, {
      skip_empty_lines: true,
      trim: true,
    }) as string[][];
    
    // Aåˆ—ï¼ˆ1åˆ—ç›®ï¼‰ã®URLã‚’æŠ½å‡ºã—ã€ç©ºè¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    const urls = records
      .map(row => row[0])
      .filter(url => url && url.trim().length > 0)
      .filter(url => url.startsWith('http://') || url.startsWith('https://'));
    
    console.log(`âœ… Found ${urls.length} site URL(s)`);
    urls.forEach((url, index) => {
      console.log(`   ${index + 1}. ${url}`);
    });
    
    return urls;
  } catch (error) {
    console.error('âŒ Error fetching site URLs:', error);
    throw error;
  }
}

/**
 * URLã‹ã‚‰ã‚µã‚¤ãƒˆåã‚’ç”Ÿæˆ
 * @param url ã‚µã‚¤ãƒˆã®URL
 * @returns ã‚µã‚¤ãƒˆå
 */
export function extractSiteName(url: string): string {
  try {
    const urlObj = new URL(url);
    const hostname = urlObj.hostname.replace('www.', '');
    
    // ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’å–å¾—ï¼ˆä¾‹: openai.com, anthropic.comï¼‰
    const parts = hostname.split('.');
    if (parts.length >= 2) {
      return parts[parts.length - 2].charAt(0).toUpperCase() + parts[parts.length - 2].slice(1);
    }
    
    return hostname;
  } catch (error) {
    console.warn(`âš ï¸  Could not parse URL: ${url}`);
    return url;
  }
}

